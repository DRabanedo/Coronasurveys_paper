as.logical(sum(1 %in% c(1,3,3)))
as.logical(2)
source("~/GitHub/CoronaSurveys_Simulations/R programs/Paper version/Paper functions script.R")
N = 1000                 # Population size
v_pop = c(1:10)           # Subpopulations vector. They are disjoint and 0 corresponds to not classifying the individual in any of them
n_pop = length(v_pop)   # Number of subpopulations
v_pop_prob =  rep(1/length(v_pop), length(v_pop)) #Probability of each subpopulation
hp_prob = 0.1             # Probability for an individual to be in the hidden population (People who have COVID-19)
n_survey = 300            # Number of individuals we draw in the survey
n_survey_hp = 50          # Number of individuals we draw in the hidden population survey
sub_memory_factor = 0     # Subpopulation memory factor (parameter to change variance of the perturbations' normal)
memory_factor = 0         # Reach memory factor (parameter to change variance of the perturbations' normal)
visibility_factor = 1     # Visibility factor (Binomial's probability)
seed = 207                # Seed
set.seed(seed)
#Graph
dim = 1    # Graph dimension
nei = 75   # Number of neighbours that each node is connected to. They are neighbors on each side of the node, so they are 2*nei connections
# before applying the randomization.
p   = 0.1  # Probability of randomize a connection. It is applied to all connections
# Study parameters
parameters = list(rep(1/2, 10), rep(1/4,10), rep(1/8,10), rep(1/16,10), rep(1/32,10), rep(1/100,10),
rep(c(1/2,1/10),5), rep(c(1/5,1/25),5), rep(c(1/4, 1/8, 1/16, 1/32, 1/64),2))
Graph_population_matrix = getData(N, v_pop, v_pop_prob, hp_prob, dim, nei, p, visibility_factor, memory_factor,sub_memory_factor)
Graph_population_matrix = getData(N, v_pop, hp_prob, dim, nei, p, visibility_factor, memory_factor,sub_memory_factor)
Graph_population_matrix = getData(N, v_pop, v_pop_prob, hp_prob, dim, nei, p, visibility_factor, memory_factor,sub_memory_factor)
getData(N,v_pop_prob,hp_prob,dim,nei,p,visibility_factor,memory_factor,sub_memory_factor)
Graph_population_matrix = getData(N,v_pop_prob,hp_prob,dim,nei,p,visibility_factor,memory_factor,sub_memory_factor)
net_sw = Graph_population_matrix[[1]]      # Population´s graph
Population = Graph_population_matrix[[2]]  # Population
Mhp_vis = Graph_population_matrix[[3]]
Population[1:4,]
N = 1000                 # Population size
v_pop = c(1:10)           # Subpopulations vector. They are disjoint and 0 corresponds to not classifying the individual in any of them
n_pop = length(v_pop)   # Number of subpopulations
v_pop_prob =  rep(1/length(v_pop), length(v_pop)) #Probability of each subpopulation
hp_prob = 0.1             # Probability for an individual to be in the hidden population (People who have COVID-19)
n_survey = 300            # Number of individuals we draw in the survey
n_survey_hp = 50          # Number of individuals we draw in the hidden population survey
sub_memory_factor = 0     # Subpopulation memory factor (parameter to change variance of the perturbations' normal)
memory_factor = 0         # Reach memory factor (parameter to change variance of the perturbations' normal)
visibility_factor = 1     # Visibility factor (Binomial's probability)
seed = 207                # Seed
set.seed(seed)
#Graph
dim = 1    # Graph dimension
nei = 75   # Number of neighbours that each node is connected to. They are neighbors on each side of the node, so they are 2*nei connections
# before applying the randomization.
p   = 0.1  # Probability of randomize a connection. It is applied to all connections
# Study parameters
parameters = list(rep(1/2, 10), rep(1/4,10), rep(1/8,10), rep(1/16,10), rep(1/32,10), rep(1/100,10),
rep(c(1/2,1/10),5), rep(c(1/5,1/25),5), rep(c(1/4, 1/8, 1/16, 1/32, 1/64),2))
Graph_population_matrix = getData(N, v_pop, v_pop_prob, hp_prob, dim, nei, p, visibility_factor, memory_factor,sub_memory_factor)
net_sw = Graph_population_matrix[[1]]      # Population´s graph
Population = Graph_population_matrix[[2]]  # Population
Mhp_vis = Graph_population_matrix[[3]]
source("~/CoronaSurveys_Simulations/R programs/Not disjoint subpopulations/Functions/Functions script.R")
source("~/IBiDat project/surveyGeneration.R")
source("~/IBiDat project/Teo_2019.R")
res = runModel(survey,v_pop_total,100)
res
res$posterior
res$posterior[1,1]
res$posterior[[1]]
res$posterior[,1]
pos = as.matrix(res$posterior)
pos
dim(pos)
pos$Su
pos[,1]
length(pos)
length(pos[,1])
survey
survey[1,]
#knownpopulation_data contains the number of individuals from each subpopulation
popindex = colnames(survey %>% dplyr::select(starts_with("KP")| HP_total_apvis ))
popindex
data0 = survey[,popindex]
data0[1:3,]
indexk = grep("K", colnames(data0))
indexk
indexu = grep("H",colnames(data0))
indexu
dataset=list(
N=dim(data0)[1],
Kk=length(indexk),
nk=data0[,indexk],
Ku=length(indexu),
nu=as.data.frame(x=data0[,indexu],col.names=indexu),
Sk=knowpopulation_data,
#Sk=as.data.frame(knowpopulation_data),
Su=rep(NA,length(indexu)))
dataset=list(
N=dim(data0)[1],
Kk=length(indexk),
nk=data0[,indexk],
Ku=length(indexu),
nu=as.data.frame(x=data0[,indexu],col.names=indexu),
Sk=v_pop_total,
#Sk=as.data.frame(knowpopulation_data),
Su=rep(NA,length(indexu)))
dataset
initialisation=list(lambda=0.1)
jagmod=jags.model(textConnection(model1),data=dataset,inits=initialisation,n.chains=2)
update(jagmod, n.iter=5000, progress.bar="text")
initialisation
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=10)
NITERATION = 50
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=10)
posterior
posterior[,1]
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=1)
posterior
as.matrix(posterior)[,1]
NITERATION
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=10)
as.matrix(posterior)[,1]
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=1)
as.matrix(posterior)[,1]
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=10)
as.matrix(posterior)[,1]
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=50,progress.bar="text",thin=10)
as.matrix(posterior)[,1]
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=50,progress.bar="text",thin=50)
as.matrix(posterior)[,1]
initialisation=list(lambda=0.1)
jagmod=jags.model(textConnection(model1),data=dataset,inits=initialisation,n.chains=1)
jagmod=jags.model(textConnection(model1),data=dataset,inits=initialisation,n.chains=1)
update(jagmod, n.iter=5000, progress.bar="text")
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=1)
dicsamples = dic.samples(jagmod,type = "pD",n.iter=20000,thin=1)
initialisation=list(lambda=0.1)
jagmod=jags.model(textConnection(model1),data=dataset,inits=initialisation,n.chains=2)
update(jagmod, n.iter=5000, progress.bar="text")
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=1)
dicsamples = dic.samples(jagmod,type = "pD",n.iter=20000,thin=1)
results = list(indexk=indexk,indexu=indexu,dataset = dataset,posterior=posterior,dicsamples=dicsamples)
as.matrix(results$posterior)[,1]
NITERATION
initialisation=list(lambda=0.1)
jagmod=jags.model(textConnection(model1),data=dataset,inits=initialisation,n.chains=2)
update(jagmod, n.iter=5000, progress.bar="text")
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=NITERATION)
posterior
posterior[[1]]
posterior[[1]][,1]
posterior[[1]][1,1]
posterior[[1]][2,1]
as.matrix(posterior[[1]])
dicsamples = dic.samples(jagmod,type = "pD",n.iter=20000,thin=NITERATION)
results = list(indexk=indexk,indexu=indexu,dataset = dataset,posterior=posterior,dicsamples=dicsamples)
as.matrix(results$posterior)[,1]
results$posterior[[1]]
dim(results$posterior)
dim(results$posterior[[1]])
initialisation=list(lambda=0.1)
jagmod=jags.model(textConnection(modelTeo),data=dataset,inits=initialisation,n.chains=2)
pos
pos[[1]]
initialisation=list(lambda=0.1)
jagmod=jags.model(textConnection(model1),data=dataset,inits=initialisation,n.chains=2)
update(jagmod, n.iter=5000, progress.bar="text")
posterior = coda.samples(jagmod, c("alpha","lambda","tau","Su"),n.iter=NITERATION,progress.bar="text",thin=1)
dicsamples = dic.samples(jagmod,type = "pD",n.iter=20000,thin=1)
results = list(indexk=indexk,indexu=indexu,dataset = dataset,posterior=posterior,dicsamples=dicsamples)
results$posterior
results$posterior[[1]]
length(results$posterior[[1]])
length(results$posterior[[1]][,1])
NITERATION
as.matrix(results$posterior[[1]])[,1]
mean(as.matrix(results$posterior[[1]])[,1])
source("~/GitHub/CoronaSurveys_Simulations/R programs/Paper version/Paper functions script.R")
# Teo et al. (2019) model
#########################
library(rjags)
##### Packages #####
library(igraph)    #
library(stringr)   #
library(ggplot2)   #
# Seed #
seed = 207
set.seed(seed)
# Network #
dim = 1
size = 10000
nei = 75
loops = FALSE
multiple = FALSE
# Loop #
iterations = 1
p_iter = 0.1
degree_df = data.frame(row.names = c(1:(iterations*size)))
degree_vect = c()
degree_loop = rep(NA, size)
# Degree calculation #
for (h in 1:length(p_iter)){
# Variable reset #
degree_vect = c()
degree_loop = rep(NA, size)
for (i in 1:iterations){
network = sample_smallworld(dim, size, nei, p = p_iter[h], loops, multiple)
for (j in 1:size){
degree_loop[j] = length(network[[j]][[1]])
}
degree_vect = append(degree_vect, degree_loop)
}
degree_df = cbind(degree_df, Probability = degree_vect)
names(degree_df)[dim(degree_df)[2]] = str_c("Probability_", p_iter[h])
}
getwd()
degree_summary =  degree_df$Probability_0.1
degree_var = round(var(degree_summary), digits = 2)
degree_median = median(degree_summary)
degree_max = max(degree_summary)
degree_min = min(degree_summary)
sub_title = str_c("Probability = ", p_iter, ", median = ", degree_median, ", var = ", degree_var,", min = ", degree_min, ", max = ", degree_max, ". Small World model")
plot_name = str_c("Smallword_", p_iter,".png")
degree_graph = ggplot(degree_df) +
geom_histogram( aes(x = Probability_0.1, y = ..count../sum(..count..)), binwidth = 1, color = "black", fill = "grey", alpha = 0.4) +
#geom_histogram( aes(x = Probability_0.5, y=..count../sum(..count..)), binwidth = 2, color = "red", fill = "red", alpha = 0.2) +
#geom_histogram( aes(x = Probability_0.75, y=..count../sum(..count..)), binwidth = 2, color = "blue", fill = "blue", alpha = 0.2) +
#geom_histogram( aes(x = Probability_1, y=..count../sum(..count..)), binwidth = 2, color = "yellow", fill = "yellow", alpha = 0.2) +
labs(title = "Network degree simulation",
subtitle = sub_title,
x = "Number of neighbors",
y = "Proportion")
degree_graph
source("~/GitHub/CoronaSurveys_Simulations/Simulaciones pendientes (Uniforme)/Paper functions script uniform.R")
source("~/GitHub/CoronaSurveys_Simulations/Simulaciones pendientes (Uniforme)/Paper functions script uniform.R")
vect = 1:10
for (i in vect) {
vect = c(vect,i)
}
vect
load("~/CoronaSurveys_Simulations/Archivos R/Estimators/Maltiel, R. and Baraff, A. J. (2015). NSUM/NSUM/data/Curitiba.RData")
View(Curitiba)
View(Curitiba)
View(Curitiba)
Curitiba$unknown
Curitiba$unknown/Curitiba$N
get.seed()
.Random.seed
get.seed(.Random.seed)
runif(5,0,1)
set.seed(.Random.seed)
runif(5,0,1)
set.seed(.Random.seed)
runif(5,0,1)
install.packages("C:/Users/Sergio Diaz/Downloads/NSUM_1.0.tar.gz", repos = NULL, type = "source")
y
N=
0
# Population size
N = 10000
seq(from = 10, to = N, length.out = 10)
library(dplyr)
library(xtable)
library("readxl")
library(magick)
library(kableExtra)
df = read_xlsx('C:/Users/Sergio Diaz/OneDrive/Documentos/China report/ch_survey..xlsx.xlsx')
df
df %>% ggplot2(aesx=Q10)+
geom_histogram()
hist(df,Q10)
hist(df$Q10)
df %>% ggplot2::aes(x=Q10)
df %>% ggplot2::aes(x=Q10)
ggplot()
ggplot2::ggplot(data=df,mapping = aes(Q10))+ggplot2::geom_histogram()
ggplot2::ggplot(data=df,aes(Q10))+ggplot2::geom_histogram()
ggplot2::ggplot2(data=df,aes(Q10))+ggplot2::geom_histogram()
ggplot2::ggplot(data=df,aes(Q10))+ggplot2::geom_histogram()
ggplot2::ggplot(data=df,)+ggplot2::geom_histogram()
ggplot2::ggplot(data=df,aes(x=Q10))+ggplot2::geom_histogram()
ggplot(df,aes(Q10))
ggplot2(df,aes(Q10))
library(ggplot2)
ggplot(df,mapping = aes(Q10))+geom_histogram()
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=100)
ggplot(df,mapping = aes(Q10))+geom_histogram()
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=5)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=20)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=10)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=15)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=20)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)+xlim(0,10)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)+xlim(0,10)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)
df
print(df)
df$Incoherente
df = read_xlsx('C:/Users/Sergio Diaz/OneDrive/Documentos/China report/ch_survey..xlsx.xlsx')
library(xtable)
library("readxl")
library(magick)
library(kableExtra)
df = read_xlsx('C:/Users/Sergio Diaz/OneDrive/Documentos/China report/ch_survey..xlsx.xlsx')
boxplot(df)
boxplot(df$Q10)
ggplot2::ggplot(df, mapping = aes(Q10))
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)+xlim(0,10)
library(ggplot2)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)+xlim(0,10)
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)
ggplot(df,mapping = aes(Q10))+geom_boxplot()
boxplot(df$Q10)
boxplot(df$Q10, main = "boxplot Q10")
boxplot(df$Q10, main = "boxplot Q10",xlab='l')
boxplot(df$Q10, main = "boxplot Q10",xlab='Q10')
boxplot(df)
boxplot(df$Q10, main = "boxplot Q10",xlab='Q10')
df[3:9]
df[2:9]
df[3:9]
boxplot(df[3:9],main= "boxplot preguntas")
df[12]
df[14]
df[12:22]
boxplot(df[12:22])
boxplot(df[15:22])
boxplot(df[12:22])
boxplot(df[12:15])
boxplot(df[12:16])
boxplot(df[12:17])
boxplot(df[12:22])
boxplot(df[12:22], main = "boxplot tiempos de respuesta")
boxplot(df[12:22], main = "tiempos de respuesta")
library(dplyr)
library(xtable)
library("readxl")
library(magick)
library(kableExtra)
df = read_xlsx('C:/Users/Sergio Diaz/OneDrive/Documentos/China report/ch_survey..xlsx.xlsx')
ggplot(df,mapping = aes(Q10))+geom_histogram(bins=30)
boxplot(df$Q10, main = "boxplot Q10",xlab='Q10')
boxplot(df[3:9],main= "boxplot preguntas")
sum(df$Q10)/(length(df$Q10)*100)
boxplot(df$Q10, main = "boxplot Q10",xlab='Q10')
select(df,Q10)
df2 = select(df,Q10)
filter(df2,Q10<3)
df3 = filter(df2,Q10<3)
sum(df3$Q10)/(length(df3$Q10)*100)
sum(df$Q10)/(length(df$Q10)*100)
boxplot(sqrt(df$Q10), main = "boxplot Q10",xlab='Q10')
2.5^2
source("~/.active-rstudio-document")
df2 = select(df,Q10)
df3 = filter(df2,Q10<7)
sum(df3$Q10)/(length(df3$Q10)*100)
sum(df3$Q10)/(length(df3$Q10)*100)*100
sum(df3$Q10)/(length(df3$Q10)*100)*100
sum(df$Q10)/(length(df$Q10)*100)*100
sum(df$Q10)/(length(df$Q10)*10)*100
source("~/GitHub/Coronasurveys_paper/Survey size/Scripts/Graph_surveysize.R")
library(dplyr)
library(matrixStats)
library(ggplot2)
library(stringr)
simulation_data  = read.csv("~/GitHub/CoronaSurveys_Simulations/R programs/Disjoint and no disjoint ensemble/Simulations and csv analysis/Survey size/CSV/Simulation_surveysize_notdisjoint_207.csv")
#simulation_data  = read.csv("~/GitHub/CoronaSurveys_Simulations/R programs/Disjoint and no disjoint ensemble/Simulations and csv analysis/Survey size/CSV/Simulation_surveysize_notdisjoint_207.csv")
#simulation_data_disjoint  =  read.csv("~/GitHub/CoronaSurveys_Simulations/R programs/Disjoint and no disjoint ensemble/Simulations and csv analysis/Survey size/CSV/Simulation_surveysize_disjoint_207.csv")
simulation_data  = read.csv("~/GitHub/Coronasurveys_paper/Survey size/Simulation_surveysize_notdisjoint_sir_sw_2022.csv")
simulation_data_disjoint  =  read.csv("~/GitHub/Coronasurveys_paper/Survey size/Simulation_surveysize_disjoint_sir_sw_2022.csv")
source("~/GitHub/Coronasurveys_paper/Survey size/Scripts/Graph_surveysize.R")
source("~/GitHub/Coronasurveys_paper/Functions script.R")
source("~/GitHub/Coronasurveys_paper/Survey size/Scripts/Graph_surveysize.R")
Nh_real_dataframe = dplyr::select(simulation_data, starts_with("Nh_real"))
Nh_basic_sum_dataframe = dplyr::select(simulation_data, starts_with("Nh_basic_sum"))
Nh_basic_mean_dataframe = dplyr::select(simulation_data, starts_with("Nh_basic_mean"))
Nh_PIMLE_dataframe    = dplyr::select(simulation_data, starts_with("Nh_PIMLE_"))
Nh_MLE_dataframe     = dplyr::select(simulation_data, starts_with("Nh_MLE_"))
Nh_MoS_dataframe     = dplyr::select(simulation_data, starts_with("Nh_MoS_"))
Nh_GNSUM_dataframe   = dplyr::select(simulation_data, starts_with("Nh_GNSUM"))
Nh_basic_sum_analysis      = data_analysis(Nh_basic_sum_dataframe, Nh_real_dataframe)
Nh_basic_mean_analysis     = data_analysis(Nh_basic_mean_dataframe, Nh_real_dataframe)
Nh_PIMLE_analysis     = data_analysis(Nh_PIMLE_dataframe, Nh_real_dataframe)
Nh_MLE_analysis     = data_analysis(Nh_MLE_dataframe, Nh_real_dataframe)
Nh_MoS_analysis     = data_analysis(Nh_MoS_dataframe, Nh_real_dataframe)
Nh_GNSUM_analysis  = data_analysis(Nh_GNSUM_dataframe, Nh_real_dataframe)
Nh_MLE_dataframe
library(ggplot2)
library(dplyr)
library(data.table)
tns = function(df){
#transpose data frame
df_t <- transpose(df)
#redefine row and column names
rownames(df_t) <- colnames(df)
colnames(df_t) <- rownames(df)
return(df_t)
}
################################################################################
data = read.csv("~/GitHub/Coronasurveys_paper/Subpopulation size/CSV/Simulations_subpopulationsize_notdisjoint_bay_207.csv")
df_MLE        = tns(dplyr::select(data, starts_with("Nh_MLE") ) )
df_MLE        = cbind('estimator' = rep('MLE',nrow(df_MLE)), df_MLE )
df_PIMLE      = tns(dplyr::select(data, starts_with("Nh_PIMLE") ) )
df_PIMLE      = cbind('estimator' = rep('PIMLE',nrow(df_PIMLE)), df_PIMLE )
df_MoS        = tns(dplyr::select(data, starts_with("Nh_MoS") ) )
df_MoS        = cbind('estimator' = rep('MoS',nrow(df_MoS)), df_MoS )
df_GNSUM      = tns(dplyr::select(data, starts_with("Nh_GNSUM") ) )
df_GNSUM      = cbind('estimator' = rep('GNSUM',nrow(df_GNSUM)), df_GNSUM )
df_Mod        = tns(dplyr::select(data, starts_with("Nh_Mod") ) )
df_Mod        = cbind('estimator' = rep('Mod',nrow(df_Mod)), df_Mod )
df_Mod
######################
# Data import
setwd("~/GitHub/Coronasurveys_paper/Network probability (small world)/Graphs")
simulation_data = read.csv("~/GitHub/Coronasurveys_paper/Network probability (small world)/CSV/Simulation_networkprobability_notdisjoint_uniform_sw_pop1_2022.csv")
simulation_data[1,]
graph_data_abserror = gen_graph_df(simulation_data, 'abserror')
plot_name = str_c("Simulation_probabilitynetwork_", seed_number, "_notdisjoint_abserror.png")
library(dplyr)
library(matrixStats)
library(ggplot2)
library(stringr)
plot_name = str_c("Simulation_probabilitynetwork_", seed_number, "_notdisjoint_abserror.png")
sub_title = str_c("Not disjoint populations plot, seed ", seed_number)
seed_number = "2022"
graph_data_abserror = gen_graph_df(simulation_data, 'abserror')
plot_name = str_c("Simulation_probabilitynetwork_", seed_number, "_notdisjoint_abserror.png")
sub_title = str_c("Not disjoint populations plot, seed ", seed_number)
png(filename = plot_name,
width = 1000, height = 600)
ggplot(graph_data_abserror) +
geom_line(aes(x = data, y =  Nh_basic_sum, col = "Nh_basic_sum")) +
#geom_line(aes(x = data, y =  Nh_basicvis_sum, col = "Nh_basicvis_sum")) +
geom_line(aes(x = data, y =  Nh_basic_mean, col = "Nh_basic_mean")) +
#geom_line(aes(x = data, y =  Nh_basicvis_mean, col = "Nh_basicvis_mean")) +
#geom_line(aes(x = data, y =  Nh_PIMLEvis, col = "Nh_PIMLEvis")) +
geom_line(aes(x = data, y =  Nh_PIMLE, col = "Nh_PIMLE")) +
geom_line(aes(x = data, y =  Nh_MLE, col = "Nh_MLE")) +
#geom_line(aes(x = data, y =  Nh_MLEvis, col = "Nh_MLEvis")) +
geom_line(aes(x = data, y =  Nh_MLEmod, col = "Nh_MLEmod")) +
#geom_line(aes(x = data, y =  Nh_MLEmodvis, col = "Nh_MLEvismod")) +
geom_line(aes(x = data, y =  Nh_MoS, col = "Nh_MoS")) +
#geom_line(aes(x = data, y =  Nh_MoSvis, col = "Nh_MoSvis")) +
geom_line(aes(x = data, y =  Nh_GNSUM, col = "Nh_GNSUM")) +
geom_line(aes(x = data, y =  Nh_TEO, col = "Nh_TEO")) +
#geom_line(aes(x = data, y =  Nh_TEOvis, col = "Nh_TEOvis")) +
geom_line(aes(x = data, y =  Nh_Zheng, col = "Nh_Zheng")) +
#geom_line(aes(x = data, y =  Nh_Zhengvis, col = "Nh_Zhengvis")) +
scale_color_discrete("Legend") +
labs(title = "Simulations based on the network probability",
subtitle = sub_title,
x = "Network probability",
y = "Mean Absolute Error")
graph_data_abserror = gen_graph_df(simulation_data, 'abserror')
source("~/GitHub/CoronaSurveys_Simulations/R programs/Paper version/Functions script.R")
graph_data_abserror = gen_graph_df(simulation_data, 'abserror')
source("~/GitHub/Coronasurveys_paper/Functions script.R")
graph_data_abserror = gen_graph_df(simulation_data, 'abserror')
plot_name = str_c("Simulation_probabilitynetwork_", seed_number, "_notdisjoint_abserror.png")
sub_title = str_c("Not disjoint populations plot, seed ", seed_number)
png(filename = plot_name,
width = 1000, height = 600)
ggplot(graph_data_abserror) +
geom_line(aes(x = data, y =  Nh_basic_sum, col = "Nh_basic_sum")) +
#geom_line(aes(x = data, y =  Nh_basicvis_sum, col = "Nh_basicvis_sum")) +
geom_line(aes(x = data, y =  Nh_basic_mean, col = "Nh_basic_mean")) +
#geom_line(aes(x = data, y =  Nh_basicvis_mean, col = "Nh_basicvis_mean")) +
#geom_line(aes(x = data, y =  Nh_PIMLEvis, col = "Nh_PIMLEvis")) +
geom_line(aes(x = data, y =  Nh_PIMLE, col = "Nh_PIMLE")) +
geom_line(aes(x = data, y =  Nh_MLE, col = "Nh_MLE")) +
#geom_line(aes(x = data, y =  Nh_MLEvis, col = "Nh_MLEvis")) +
geom_line(aes(x = data, y =  Nh_MLEmod, col = "Nh_MLEmod")) +
#geom_line(aes(x = data, y =  Nh_MLEmodvis, col = "Nh_MLEvismod")) +
geom_line(aes(x = data, y =  Nh_MoS, col = "Nh_MoS")) +
#geom_line(aes(x = data, y =  Nh_MoSvis, col = "Nh_MoSvis")) +
geom_line(aes(x = data, y =  Nh_GNSUM, col = "Nh_GNSUM")) +
geom_line(aes(x = data, y =  Nh_TEO, col = "Nh_TEO")) +
#geom_line(aes(x = data, y =  Nh_TEOvis, col = "Nh_TEOvis")) +
geom_line(aes(x = data, y =  Nh_Zheng, col = "Nh_Zheng")) +
#geom_line(aes(x = data, y =  Nh_Zhengvis, col = "Nh_Zhengvis")) +
scale_color_discrete("Legend") +
labs(title = "Simulations based on the network probability",
subtitle = sub_title,
x = "Network probability",
y = "Mean Absolute Error")
dev.off()
ggplot(graph_data_abserror) +
geom_line(aes(x = data, y =  Nh_basic_sum, col = "Nh_basic_sum")) +
#geom_line(aes(x = data, y =  Nh_basicvis_sum, col = "Nh_basicvis_sum")) +
geom_line(aes(x = data, y =  Nh_basic_mean, col = "Nh_basic_mean")) +
#geom_line(aes(x = data, y =  Nh_basicvis_mean, col = "Nh_basicvis_mean")) +
#geom_line(aes(x = data, y =  Nh_PIMLEvis, col = "Nh_PIMLEvis")) +
geom_line(aes(x = data, y =  Nh_PIMLE, col = "Nh_PIMLE")) +
geom_line(aes(x = data, y =  Nh_MLE, col = "Nh_MLE")) +
#geom_line(aes(x = data, y =  Nh_MLEvis, col = "Nh_MLEvis")) +
geom_line(aes(x = data, y =  Nh_MLEmod, col = "Nh_MLEmod")) +
#geom_line(aes(x = data, y =  Nh_MLEmodvis, col = "Nh_MLEvismod")) +
geom_line(aes(x = data, y =  Nh_MoS, col = "Nh_MoS")) +
#geom_line(aes(x = data, y =  Nh_MoSvis, col = "Nh_MoSvis")) +
geom_line(aes(x = data, y =  Nh_GNSUM, col = "Nh_GNSUM")) +
geom_line(aes(x = data, y =  Nh_TEO, col = "Nh_TEO")) +
#geom_line(aes(x = data, y =  Nh_TEOvis, col = "Nh_TEOvis")) +
geom_line(aes(x = data, y =  Nh_Zheng, col = "Nh_Zheng")) +
#geom_line(aes(x = data, y =  Nh_Zhengvis, col = "Nh_Zhengvis")) +
scale_color_discrete("Legend") +
labs(title = "Simulations based on the network probability",
subtitle = sub_title,
x = "Network probability",
y = "Mean Absolute Error")
graph_data_abserror = gen_graph_df(simulation_data, 'abserror')
graph_data_abserror
dplyr::select(simulation_data, starts_with('Nh_MLE_')
)
